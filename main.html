<!DOCTYPE html>

<html>

<head>
	<link rel="stylesheet" href="styles.css">
</head>

<body>
	<h1>Time Complexity.</h1>
	<p>Time complexity is a measure of the amount of time an algorithm takes to execute as a function of its input size. It is an essential factor in determining the performance and scalability of a program, as inefficient algorithms can lead to slow execution times and unresponsive applications. By analyzing an algorithm's time complexity, developers can make informed decisions about which algorithms are best suited for a particular task, helping to ensure optimal performance.
</p>
	
	<p>Some algorithms perform better than others. We always prefer to select an efficient algorithm, hence metrics for assessing algorithm efficiency would be useful.

The complexity of an algorithm is a function that describes the algorithm's efficiency in terms of the amount of data it must process. There are usually natural units for the domain and range of this function. There are two basic complexity metrics of the efficiency of an algorithm:

Time complexity is a function that describes how long an algorithm takes in terms of the quantity of input it receives.
Space complexity is a function that describes how much memory (space) an algorithm requires to the quantity of input to the method.</p>

	<h1>Space Complexity</h1>
	<b><p>Space complexity refers to the total amount of memory space used by an algorithm/program, including the space of input values for execution. Calculate the space occupied by variables in an algorithm/program to determine space complexity.

However, people frequently confuse Space-complexity with auxiliary space. Auxiliary space is simply extra or temporary space, and it is not the same as space complexity. To put it another way,

Auxiliary space + space use by input values = Space Complexity

The best algorithm/program should have a low level of space complexity. The less space required, the faster it executes.
	</b></p>
		<p>This notation describes an asymptotic upper bound of the asymptotic Notations. It denotes the algorithms scalability and performance. It essentially gives you the worst-case scenario of an algorithmâ€™s growth rate. What it tells you is that the amount of space that the algorithm in question takes will not grow any faster than this f(x), but it could grow at a slower pace.

Here are some examples of expressing space complexity using big-O notation, starting from the slowest space growth to the fastest. 

O(1): This signifies constant complexity. It takes the same amount of space irrespective of the input size.
O(log n): This signifies logarithmic complexity. It takes up space proportional to the log of the input size.
O(n): This denotes linear complexity. It takes space directly proportional to the input size.
O(n log n):This denotes log-linear or quasilinear complexity. It is also called linearithmic. Its space complexity increases proportionally to the input size and a logarithmic factor.
O(n2): This denotes square or polynomial complexity. Space complexity increases proportionally to the square of the input size.</p>
    <script type="text/javascript" src="./script.js">
</script>

</body>

</html>
